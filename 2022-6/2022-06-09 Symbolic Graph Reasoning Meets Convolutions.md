# Symbolic Graph Reasoning Meets Convolutions
## 摘要
为了在卷积网络基础上赋予语义全局推理的能力，提出了一个符号图推理(SGR)层，它对一组符号节点进行推理，每个节点显示表示先验的知识图中的每种语义。SGR由3部分组成：
1. **局部信息到语义节点的投票模块**：由局部特征信息投票聚合成节点特征
2. **图推理模块**：通过在知识图上传播实现全局语义一致性
3. **语义到局部信息的映射模块**：学习节点和局部特征信息的新关联，将更新后的节点特征映射回局部特征信息

该方法可以嵌入任何卷积层中，实验表明，该方法可以显著改善语义分割、图像分类等任务的性能。

## 介绍
卷积神经网络在图像分类、图像分割、目标识别等任务取得重大进展，但其可以生效是在于深层复杂的卷积层的堆积，这样的网络缺乏对复杂任务的全局推理能力。一些任务通过修改模型结构解决该问题，但是它们不能用显式的方式增强特征，然而对外部知识的视觉推理对人类来说是至关重要的。

该方法提出符号图推理(SGR)模块，通过引入外部知识图来实现显式的全局特征推理。
*此处的符号(Sign)表示具有明确语义的节点*

SGR模块由3部分组成，如下图所示：
1. **局部到语义的投票模块**：对所有局部特征信息进行投票，得到每个符号节点的视觉特征
2. **图推理模块**：在先验知识图进行信息传播，更新所有符号节点的视觉特征
3. **语义到局部的映射模块**：学习符号节点和局部特征之间的关联，将更新后的节点特征投影回局部特征

![[Pasted image 20220609175220.png]]

SGR模块可以根据不同的知识图嵌入到任意卷积层之间，赋予卷积层显式全局推理能力。

## 方法
### 知识图的构造
常识知识图一般用来描述实体之间不同的相关性，将知识图表示为$G=(N,E)$，其中$N$和$E$表示符号集和边集。关系可以是归属(心脏属于身体)、共生(衣服和裤子总是共同出现)或更高层的语义抽象(人骑马)等。

### 局部到语义的投票模块
给定卷积层的局部特征张量，目标是利用外部结构化知识进行全局图推理，增强局部特征。因此，首先要将局部特征总结为符号节点来表示。对于第$l$个卷积层输出的特征张量$X^l\in\mathbb{R}^{H^l\times W^l\times D^l}$，该模块要利用$X^l$得到符号节点特征$H^{ps}\in\mathbb{R}^{M\times D^c}$，其中$M=|N|$是节点的数量，$D^c$是每个节点的特征维数。将上述过程概括为函数$\phi$：
$$
H^{ps}=\phi(A^{ps},X^l,W^{ps}),
$$
其中$W^{ps}\in\mathbb{R}^{D^l\times D^c}$是负责将每个局部特征转换维度为$D^c$的可训练矩阵，$A^{ps}\in\mathbb{R}^{H^l\times W^l\times M}$表示所有局部特征对每个符号节点的投票权，即
$$
H_n^{ps}=\sum_{x_i}a_{x_i\to n}x_iW^{ps},a_{x_i\to n}=\frac{\exp({W_n^a}^Tx_i)}{\sum_{n\in N}\exp({W_n^a}^Tx_i)}.
$$
其中$W_a\in\mathbb{R}^{D^l\times M}$是负责计算投票权的可训练矩阵，通过对所有节点作softmax，规范每个节点的总权重为1，从而实现自适应地对不同符号节点进行投票。

> 感觉论文讲的有点乱，其实就是通过两个卷积得到每个局部特征对每个符号节点的投票权重$A^{ps}$和每个局部特征转换维度后的特征$W^{ps}$，之后将$A^{ps}$归一化后与局部特征相乘(即将每个局部特征按其对每个节点投票权重加权求和，得到每个节点的特征)，得到节点表示$H^{ps}$

### 图推理模块
结合每个节点的词嵌入进行图推理。对于每个符号节点$n\in N$，使用现有的词向量$S=\{s_n\},s_n\in\mathbb{R^K}$作为语义嵌入，通过GCN的方式进行传播，得到更新后的特征$H^g$
$$
H^g=\sigma(A^gBW^g),
$$
其中$B=[\sigma(H^{ps}),S]\in\mathbb{R}^{M\times(D^c+K)}$表示将投票特征经过激活函数后与语义嵌入拼接得到的特征。$W^g$是可训练的权重矩阵。$A^g$是根据$E$中边的连接方式定义的邻接矩阵，可以是软权重e.g$(0.8)$或硬权重$(\{0, 1\})$。

根据GCN公式对$A^g$进行标准化处理，使所有行和为1，从而保证特征不改变其规模，从而有
$$
H^g=\sigma(\hat{Q}^{-1/2}\hat{A}^g\hat{Q}^{-1/2}BW^g),
$$
其中$\hat{A}^g=A_g+I$表示添加自连接，$Q$是$\hat{A}^g$的度矩阵。

### 语义到局部的映射模块
最后要利用更新后的符号节点特征$H^g\in\mathbb{R}^{M\times D^v}$提高每个局部特征的表示能力。由于图推理改变了每个符号节点的特征分布，找到符号节点到所有局部特征的映射是一个关键问题。通过评估每个符号节点$h_g$与每个局部特征$x_i$的兼容性来计算映射权重$a_{h^g\to x_i}\in A^{sp}$
$$
a_{h^g\to x_i}=\frac{\exp({W^s}^T[h^g,x_i])}{\sum_{x_i}\exp({W^s}^T[h_g,x_i])},
$$
其中$W_s\in\mathbb{R}^{D^c\times D^l}$是一个可训练的权重矩阵，从而得到标准化的兼容性矩阵$A^{sp}\in\mathbb{R}^{H\times W\times M}$，softmax保证每个节点的总兼容性权重为1。最后得到更新后的局部特征
$$
X^{l+1}=\sigma(A^{sp}H^gW^{sp}) + X^l,
$$
其中$W^{sp}\in\mathbb{R}^{D^c\times D^l}$是负责将维度转换回$D^l$的可训练权重矩阵，并利用残差连接增强表示能力。
![[Pasted image 20220609195703.png]]

## 实验
语义分割上的效果如下图。
![[Pasted image 20220609193418.png]]
![[Pasted image 20220609193457.png]]