# Beyond Grids：Learning Graph Representations for Visual Recognition
## 摘要
提出了一个基于二维特征映射的学习图表示方法，用于解决特征之间的长依赖问题。方法有投影、图卷积、重投影三步：
1. 投影是将特征图按区域聚集成若干个顶点，并根据顶点间的相似度计算边
2. 图卷积即标准的GCN前向传播；重投影是将更新后的顶点特征
3. 重投影是将每个顶点按距离加权的方式投影回原区域

该方法支持端到端训练，并容易集成到现有网络中，在语义分割、目标检测等领域都优于最先进的方法。

## 介绍
传统的CNN在CV领域取得巨大的成功，通过堆叠卷积、BN、池化等操作，CNN可以非常有效地提取局部信息，并通过一个巨大的感受野捕获长距离的依赖关系。

然而，有研究表明CNN的有效感受野的尺寸往往小于理论感受野，并且离中心点越远的像素的权重越小，这意味着即使堆叠大量的卷积层，CNN提取目标上下文关系的效果依然很低。一个新的想法是使用图像区域进行上下文推理和识别，这种方法捕获依赖关系的效果大大提升。

具体来说，该方法包括图投影、图卷积和图重投影：
1. 图投影将一个二维特征映射转化为一个图，其中具有相似特征的像素被分配到相同的顶点。它进一步编码每个顶点的特征，并为每个样本计算邻接矩阵。
2. 图卷积利用图结构上的卷积，并根据邻接矩阵更新顶点特征。
3. 图重投影将顶点特征插值到一个二维特征映射，恢复原先像素到顶点的分配

该方法相比全卷积网络，在语义分割上提高了7%，优于最先进的上下文建模方法。对于目标检测和实例分割，该方法相比Mask RCNN提高了1%。

## 方法
### 概述
![[Pasted image 20220531200000.png]]

对于特征图$X\in\mathbb{R}^{d\times H\times W}$，其中每个特征点$x_{ij}\in\mathbb{R}^{d}$是一个d维的特征向量。图卷积模块(GCU)包含3个步骤：
1. **图投影**：将特征图$X$投影为图$G=(V,\varepsilon)$，其中$V,\varepsilon$分别表示顶点和边。图投影将具有相似特征的特征点分配到同一顶点，这是一个软分配，即一个特征点可能按权重被分给多个区域。投影后特征点聚合形成顶点特征$Z\in\mathbb{R}^{d\times|V|}$。基于Z计算顶点之间的距离，计算邻接矩阵
2. **图卷积**：根据邻接矩阵对G进行卷积，卷积可以叠加多次，并使用非线性激活函数连接。如果G全连通，图卷积就回具有图上所有顶点的接受域，从而捕获全局上下文信息。图卷积输出的特征为$\tilde{Z}\in\mathbb{R}^{|V|\times\tilde{d}}$
3. **图重投影**：将$\tilde{Z}$映射回X中

### 图卷积模块
#### 图投影
图投影包含两个可训练参数$W\in\mathbb{R}^{d\times|V|},\Sigma\in\mathbb{R}^{d\times|V|}$，其中顶点数|V|是经验值。W中每列$w_k\in\mathbb{R}^{d}$指定顶点k的位置。通过计算$q_{ij}^k$衡量$x_{ij}$分配到$w_k$的权重
$$
q_{ij}^k=\frac{\exp(-||(x_{ij}-w_k)/\sigma_k||_2^2/2)}{\sum_k\exp(-||(x_{ij}-w_k)/\sigma_k||_2^2/2)},
$$
其中$\sigma_k$是$\Sigma$的第k列，并通过sigmoid约束其范围在0~1之间。

> 个人理解：W和$\Sigma$存放了各个顶点在各个维度的均值和方差。通过$||(x_{ij}-w_k)/\sigma_k||_2^2/2$的操作，得到特征点$x_{ij}$对于顶点k的距离，距离越小的权重越高，因此将特征点$x_{ij}$对于所有顶点的距离取负数中作softmax，从而给$x_{ij}$最靠近的顶点赋予最大权重

之后根据权重计算每个顶点的特征，并进行标准化处理，得到$Z\in\mathbb{R}^{d\times|V|}$，其中Z的第k列$z_k$如下
$$
z_k'=\frac{1}{\sum_{ij}q_{ij}^k}\sum_{ij}q_{ij}^k(x_{ij}-w_k)/\sigma_k,
$$
$$
z_k=\frac{z_k'}{||z_k'||_2}.
$$
![[Beyond Grids]]

之后根据边之间的距离计算邻接矩阵
$$
A=Z^TZ\in\mathbb{R}^{|V|\times|V|}.
$$

#### 图卷积
根据GCN公式更新
$$
\tilde{Z}=f(AZ^TW),
$$
其中$W\in\mathbb{R}^{d\times \tilde{d}}$为可学习参数。

#### 图重投影
$$
\tilde{X}=Q\tilde{Z}^T.
$$

### 图表示学习
在训练过程中，GCU可能会将整个图像分配给单个顶点，但是对于不同的图像使用不同的顶点。针对这一问题有两种策略：
1. **根据聚类初始化**：使用KMeans获取每个顶点的均值和方差，作为W和$\Sigma$的初始化值
2. **正则化**：加入一个先验分布p，约束$p(Q)=\sum_{ij}q_{ij}^k\in\mathbb{R}^{|V|}$的分布，即加入一个损失函数$L_{div}=KL(p(Q)||p)$，作者此处将p设为均匀分布

## 实验
在设置2、4、8、32个顶点时，划分的区域如下图。
![[Pasted image 20220531203602.png]]

目标检测和实例分割的效果如下表。
![[Pasted image 20220531203705.png]]
